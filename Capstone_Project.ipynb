{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWM9XBJxygkFgfuSBjei7l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shweetak/Sweta/blob/main/Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGNpSGaU8gHn"
      },
      "outputs": [],
      "source": [
        "#install Apache Spark 3.0.1 with Hadoop 2.7 from here.\n",
        "!wget https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "\n",
        "# Now, we just need to unzip that folder.\n",
        "!tar -xvzf spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!pip install findspark\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Customer table and inserting data"
      ],
      "metadata": {
        "id": "mlVNjhxESLyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "db = sqlite3.connect('customers.db')\n",
        "\n",
        "query_create_table = 'CREATE TABLE customers(customer_id INTEGER, first_name VARCHAR, last_name VARCHAR, date_of_birth DATE)'\n",
        "db.execute(query_create_table)\n",
        "\n",
        "query_insert_data = '''\n",
        "INSERT INTO customers (customer_id, first_name, last_name, date_of_birth) VALUES\n",
        "(1, 'John', 'Doe', '1980-05-15'),\n",
        "(2, 'Jane', 'Smith', '1992-08-21'),\n",
        "(3, 'Alice', 'Johnson', '1975-02-10'),\n",
        "(4, 'Sarah', 'Jones', '1988-12-03'),\n",
        "(5, 'David', 'Brown', '1995-04-18'),\n",
        "(6, 'Emma', 'Miller', '1982-07-25');\n",
        "'''\n",
        "\n",
        "db.execute(query_insert_data)\n",
        "\n",
        "query_select_all = 'SELECT * FROM customers'\n",
        "df_customers = pd.read_sql_query(query_select_all, db)\n",
        "df_cust = spark.createDataFrame(df_customers)\n",
        "df_cust.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4P6YR0DREWp",
        "outputId": "2dc16c46-a95c-4759-ce30-bf39ed0fd450"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py:327: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+-------------+\n",
            "|customer_id|first_name|last_name|date_of_birth|\n",
            "+-----------+----------+---------+-------------+\n",
            "|          1|      John|      Doe|   1980-05-15|\n",
            "|          2|      Jane|    Smith|   1992-08-21|\n",
            "|          3|     Alice|  Johnson|   1975-02-10|\n",
            "|          4|     Sarah|    Jones|   1988-12-03|\n",
            "|          5|     David|    Brown|   1995-04-18|\n",
            "|          6|      Emma|   Miller|   1982-07-25|\n",
            "+-----------+----------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating braches dataframe"
      ],
      "metadata": {
        "id": "RMSa0XFQSVlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CapstoneProject\").master(\"local\").getOrCreate()\n",
        "\n",
        "json_file_path = \"/content/branches.json\"\n",
        "\n",
        "with open(json_file_path, 'r') as file:\n",
        "    json_data = json.load(file)\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"branch_id\", IntegerType(), True),\n",
        "    StructField(\"branch_name\", StringType(), True),\n",
        "    StructField(\"location\", StringType(), True),\n",
        "])\n",
        "\n",
        "rows = [(branch[\"branch_id\"], branch[\"branch_name\"], branch[\"location\"]) for branch in json_data[\"branches\"]]\n",
        "branches = spark.createDataFrame(rows, schema=schema)\n",
        "\n",
        "branches.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BfVEcw3-yk9",
        "outputId": "bc08d260-a70d-4c6d-8e4c-a341073a2bca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------------+-------------+\n",
            "|branch_id|branch_name    |location     |\n",
            "+---------+---------------+-------------+\n",
            "|1        |Main Branch    |Downtown City|\n",
            "|2        |Suburban Branch|Suburbville  |\n",
            "|3        |Regional Branch|Regional City|\n",
            "+---------+---------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating accounts dataframe"
      ],
      "metadata": {
        "id": "TNL5HFagS6uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CapstoneProject\").master(\"local\").getOrCreate()\n",
        "\n",
        "json_file_path = \"/content/accounts.json\"\n",
        "\n",
        "with open(json_file_path, 'r') as file:\n",
        "    json_data = json.load(file)\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"account_id\", IntegerType(), True),\n",
        "    StructField(\"customer_id\", IntegerType(), True),\n",
        "    StructField(\"employee_id\", IntegerType(), True),\n",
        "    StructField(\"account_type\", StringType(), True),\n",
        "    StructField(\"balance\", IntegerType(), True),\n",
        "])\n",
        "\n",
        "rows = [\n",
        "    (\n",
        "        account[\"account_id\"],\n",
        "        account[\"customer_id\"],\n",
        "        account[\"employee_id\"],\n",
        "        account[\"account_type\"],\n",
        "        account[\"balance\"]\n",
        "    ) for account in json_data[\"accounts\"]\n",
        "]\n",
        "accounts = spark.createDataFrame(rows, schema=schema)\n",
        "\n",
        "\n",
        "accounts.show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiRmYLw3Ec1X",
        "outputId": "47d5862d-a610-44e6-e69a-0c68a5e4a1e8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----------+------------+-------+\n",
            "|account_id|customer_id|employee_id|account_type|balance|\n",
            "+----------+-----------+-----------+------------+-------+\n",
            "|1         |1          |2          |Savings     |5000   |\n",
            "|2         |1          |3          |Checking    |1000   |\n",
            "|3         |2          |4          |Savings     |8000   |\n",
            "|4         |3          |1          |Checking    |3000   |\n",
            "|5         |2          |2          |Checking    |2500   |\n",
            "|6         |3          |3          |Savings     |6000   |\n",
            "|7         |4          |4          |Checking    |12000  |\n",
            "|8         |5          |2          |Savings     |3000   |\n",
            "+----------+-----------+-----------+------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating transaction dataframe"
      ],
      "metadata": {
        "id": "ZwRYiX-bXpxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "spark = SparkSession.builder.appName(\"CapstoneProject\").master(\"local\").getOrCreate()\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"transaction_id\", IntegerType()),\n",
        "    StructField(\"account_id\", IntegerType()),\n",
        "    StructField(\"transaction_type\", StringType()),\n",
        "    StructField(\"amount\", IntegerType()),\n",
        "    StructField(\"transaction_date\", TimestampType())\n",
        "])\n",
        "transaction = spark.read.csv(path = \"/content/transactions.csv\", header=True, schema=schema)\n",
        "transaction.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQi4CY1GTV22",
        "outputId": "b886cb20-5f72-4986-adc7-5138a2560321"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+----------------+------+-------------------+\n",
            "|transaction_id|account_id|transaction_type|amount|transaction_date   |\n",
            "+--------------+----------+----------------+------+-------------------+\n",
            "|1             |1         |Deposit         |1000  |2023-01-15 08:30:00|\n",
            "|2             |1         |Withdrawal      |500   |2023-02-02 12:45:00|\n",
            "|3             |2         |Deposit         |2000  |2023-03-10 15:20:00|\n",
            "|4             |3         |Withdrawal      |1000  |2023-04-05 10:10:00|\n",
            "|5             |4         |Deposit         |1500  |2023-05-20 09:00:00|\n",
            "|6             |5         |Deposit         |2000  |2023-06-12 11:30:00|\n",
            "|7             |3         |Withdrawal      |800   |2023-07-08 14:15:00|\n",
            "|8             |2         |Deposit         |3000  |2023-08-22 16:45:00|\n",
            "|9             |4         |Withdrawal      |1500  |2023-09-14 09:30:00|\n",
            "|10            |1         |Deposit         |1200  |2023-10-01 10:00:00|\n",
            "+--------------+----------+----------------+------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating employees datframe"
      ],
      "metadata": {
        "id": "7B7ccM34XueB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "tree = ET.parse('/content/employees.xml')\n",
        "root = tree.getroot()\n",
        "\n",
        "data = []\n",
        "for child in root:\n",
        "    record = {}\n",
        "    for subchild in child:\n",
        "        record[subchild.tag] = subchild.text\n",
        "    data.append(record)\n",
        "\n",
        "employees = pd.DataFrame(data)\n",
        "df_emp = spark.createDataFrame(employees)\n",
        "df_emp.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiamtQNLUdLH",
        "outputId": "bde94d72-d1de-4397-f925-7927e9bb4129"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+----------+---------+--------+\n",
            "|employee_id|branch_id|first_name|last_name|position|\n",
            "+-----------+---------+----------+---------+--------+\n",
            "|          1|        2|      Mike|  Johnson| Manager|\n",
            "|          2|        3|     Emily| Williams|  Teller|\n",
            "|          3|        2|    Robert|    Davis|  Teller|\n",
            "|          4|        3|    Olivia|   Wilson|  Teller|\n",
            "|          5|        2|    Daniel|  Johnson| Analyst|\n",
            "|          6|        3|    Sophia|    Clark| Manager|\n",
            "|          7|        2|      Mike|  Johnson| Manager|\n",
            "|          8|        3|     Emily| Williams|  Teller|\n",
            "|          9|        2|    Robert|    Davis|  Teller|\n",
            "|         10|        3|    Olivia|   Wilson|  Teller|\n",
            "|         11|        2|    Daniel|  Johnson| Analyst|\n",
            "|         12|        3|    Sophia|    Clark| Manager|\n",
            "+-----------+---------+----------+---------+--------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py:327: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating loan dataframe"
      ],
      "metadata": {
        "id": "9ZvQNMCtX0N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "spark = SparkSession.builder.appName(\"CapstoneProject\").master(\"local\").getOrCreate()\n",
        "\n",
        "loans = spark.read.csv(path = \"/content/loans.csv\", header=True)\n",
        "loans.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rrPqgAJVFHY",
        "outputId": "426745cb-8aea-48a5-f988-ab576166626b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+-----------+-------------+----------+----------+------+\n",
            "|loan_id|customer_id|loan_amount|interest_rate|start_date|end_date  |status|\n",
            "+-------+-----------+-----------+-------------+----------+----------+------+\n",
            "|1      |1          |10000      |0.05         |2023-01-01|2023-12-31|Active|\n",
            "|2      |1          |15000      |0.04         |2023-02-15|2023-12-31|Active|\n",
            "|3      |2          |8000       |0.03         |2023-03-20|2023-11-30|Active|\n",
            "|4      |3          |20000      |0.05         |2023-01-10|2023-10-31|Active|\n",
            "+-------+-----------+-----------+-------------+----------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating payment_history dataframe"
      ],
      "metadata": {
        "id": "IZCpXGyqX351"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "spark = SparkSession.builder.appName(\"CapstoneProject\").master(\"local\").getOrCreate()\n",
        "\n",
        "payment_history = spark.read.csv(path = \"/content/payment_history.csv\", header=True)\n",
        "payment_history = payment_history.withColumn(\"payment_id\", monotonically_increasing_id())\n",
        "payment_history.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6fuxdDxVvUD",
        "outputId": "00d9ae14-5026-450c-a889-e44113051a60"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+------------+-----------+\n",
            "|payment_id|loan_id|payment_date|amount_paid|\n",
            "+----------+-------+------------+-----------+\n",
            "|0         |1      |2023-03-01  |2000.0     |\n",
            "|1         |1      |2023-04-01  |1500.0     |\n",
            "|2         |2      |2023-04-10  |1000.0     |\n",
            "|3         |3      |2023-02-20  |3000.0     |\n",
            "|4         |3      |2023-03-15  |2500.0     |\n",
            "+----------+-------+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic reports"
      ],
      "metadata": {
        "id": "tGlU2VFCX-Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1. Write a spark dataframe to show the balance amount for an account_id = 1\n",
        "\n",
        "result_df = accounts.filter(accounts[\"account_id\"] == 1).select(\"balance\")\n",
        "result_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud0U74inWpOn",
        "outputId": "d02f1fcd-d076-4374-acda-b1273a7c9e95"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|balance|\n",
            "+-------+\n",
            "|5000   |\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2: List Transactions for an account_id = 1:\n",
        "\n",
        "account_transactions = transaction.filter(transaction[\"account_id\"] == 1)\n",
        "account_transactions.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ6JecdnYyTL",
        "outputId": "8c4a806a-242d-420c-a631-8c2c705dac6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+----------------+------+-------------------+\n",
            "|transaction_id|account_id|transaction_type|amount|transaction_date   |\n",
            "+--------------+----------+----------------+------+-------------------+\n",
            "|1             |1         |Deposit         |1000  |2023-01-15 08:30:00|\n",
            "|2             |1         |Withdrawal      |500   |2023-02-02 12:45:00|\n",
            "|10            |1         |Deposit         |1200  |2023-10-01 10:00:00|\n",
            "+--------------+----------+----------------+------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3: List Accounts with a zero balance:\n",
        "\n",
        "zero_balance_accounts = accounts.filter(accounts[\"balance\"] == 0)\n",
        "zero_balance_accounts.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgYC8PaKZYFm",
        "outputId": "feb14bb8-e005-44d1-b021-50d997ce7729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-----------+------------+-------+\n",
            "|account_id|customer_id|employee_id|account_type|balance|\n",
            "+----------+-----------+-----------+------------+-------+\n",
            "+----------+-----------+-----------+------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4: Find the Oldest Customer\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "customers = spark.createDataFrame(df_customers)\n",
        "\n",
        "oldest_customer = customers.orderBy(\"date_of_birth\").limit(1)\n",
        "oldest_customer.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBXhWAXUZsCw",
        "outputId": "8f5ed16c-f90b-447d-b1c7-5fd4d4c0044a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py:327: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+-------------+\n",
            "|customer_id|first_name|last_name|date_of_birth|\n",
            "+-----------+----------+---------+-------------+\n",
            "|3          |Alice     |Johnson  |1975-02-10   |\n",
            "+-----------+----------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5: Calculate the Total Interest Earned Across All Accounts\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "interest_earned = transaction.agg(sum('amount').alias('total_interest_earned'))\n",
        "interest_earned.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUmzI6NrZ4_W",
        "outputId": "43dcd8d7-b478-472e-a9bf-7e5d1bd2b5e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+\n",
            "|total_interest_earned|\n",
            "+---------------------+\n",
            "|14500                |\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accounts Report"
      ],
      "metadata": {
        "id": "qB2Tbfbce9Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1: List All Accounts with Customer Information\n",
        "\n",
        "all_accounts_info = accounts.join(customers, on='customer_id', how='inner')\n",
        "\n",
        "result = all_accounts_info.select(\"customer_id\", \"first_name\", \"last_name\", \"account_id\", \"account_type\", \"balance\")\n",
        "\n",
        "result.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI6LO6rAep0t",
        "outputId": "5a4e9dc2-5718-4a47-bcfc-cf14026be4fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+----------+------------+-------+\n",
            "|customer_id|first_name|last_name|account_id|account_type|balance|\n",
            "+-----------+----------+---------+----------+------------+-------+\n",
            "|5          |David     |Brown    |8         |Savings     |3000   |\n",
            "|1          |John      |Doe      |1         |Savings     |5000   |\n",
            "|1          |John      |Doe      |2         |Checking    |1000   |\n",
            "|3          |Alice     |Johnson  |4         |Checking    |3000   |\n",
            "|3          |Alice     |Johnson  |6         |Savings     |6000   |\n",
            "|2          |Jane      |Smith    |3         |Savings     |8000   |\n",
            "|2          |Jane      |Smith    |5         |Checking    |2500   |\n",
            "|4          |Sarah     |Jones    |7         |Checking    |12000  |\n",
            "+-----------+----------+---------+----------+------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2: . Calculate Total Balance for Each Customer:\n",
        "\n",
        "total_balance_per_customer = result.groupBy(\"customer_id\", \"first_name\", \"last_name\").agg(sum(\"balance\").alias(\"total_balance\"))\n",
        "\n",
        "total_balance_per_customer.show(truncate=False)"
      ],
      "metadata": {
        "id": "8xz54vlYfOL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77fbd54-452f-4e34-f6ba-d7d3cb33d018"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+-------------+\n",
            "|customer_id|first_name|last_name|total_balance|\n",
            "+-----------+----------+---------+-------------+\n",
            "|3          |Alice     |Johnson  |9000         |\n",
            "|5          |David     |Brown    |3000         |\n",
            "|2          |Jane      |Smith    |10500        |\n",
            "|4          |Sarah     |Jones    |12000        |\n",
            "|1          |John      |Doe      |6000         |\n",
            "+-----------+----------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3: Find Customers with Multiple Accounts:\n",
        "\n",
        "customer_account_count = accounts.groupBy(\"customer_id\").agg(count(\"account_id\").alias(\"account_count\"))\n",
        "\n",
        "customers_with_multiple_accounts = customer_account_count.filter(col(\"account_count\") > 1)\n",
        "\n",
        "customers_with_multiple_accounts.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB8yiupJol62",
        "outputId": "190126bd-65c9-4eb6-c032-6dedde75bea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+\n",
            "|customer_id|account_count|\n",
            "+-----------+-------------+\n",
            "|1          |2            |\n",
            "|3          |2            |\n",
            "|2          |2            |\n",
            "+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Transaction report"
      ],
      "metadata": {
        "id": "MF6d39Q3pxOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1: List Transactions with Account and Customer Information:\n",
        "\n",
        "joined_df = transaction.join(accounts, \"account_id\").join(customers, \"customer_id\")\n",
        "new_df = joined_df.select('transaction_id','transaction_type','amount','transaction_date','customer_id','first_name','last_name','account_id','account_type')\n",
        "new_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au9lSI59piGS",
        "outputId": "2a56be92-ff0c-4d63-ac87-6ae829231c13"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------------+------+-------------------+-----------+----------+---------+----------+------------+\n",
            "|transaction_id|transaction_type|amount|transaction_date   |customer_id|first_name|last_name|account_id|account_type|\n",
            "+--------------+----------------+------+-------------------+-----------+----------+---------+----------+------------+\n",
            "|10            |Deposit         |1200  |2023-10-01 10:00:00|1          |John      |Doe      |1         |Savings     |\n",
            "|2             |Withdrawal      |500   |2023-02-02 12:45:00|1          |John      |Doe      |1         |Savings     |\n",
            "|1             |Deposit         |1000  |2023-01-15 08:30:00|1          |John      |Doe      |1         |Savings     |\n",
            "|8             |Deposit         |3000  |2023-08-22 16:45:00|1          |John      |Doe      |2         |Checking    |\n",
            "|3             |Deposit         |2000  |2023-03-10 15:20:00|1          |John      |Doe      |2         |Checking    |\n",
            "|9             |Withdrawal      |1500  |2023-09-14 09:30:00|3          |Alice     |Johnson  |4         |Checking    |\n",
            "|5             |Deposit         |1500  |2023-05-20 09:00:00|3          |Alice     |Johnson  |4         |Checking    |\n",
            "|7             |Withdrawal      |800   |2023-07-08 14:15:00|2          |Jane      |Smith    |3         |Savings     |\n",
            "|4             |Withdrawal      |1000  |2023-04-05 10:10:00|2          |Jane      |Smith    |3         |Savings     |\n",
            "|6             |Deposit         |2000  |2023-06-12 11:30:00|2          |Jane      |Smith    |5         |Checking    |\n",
            "+--------------+----------------+------+-------------------+-----------+----------+---------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2: Calculate Average Transaction Amount\n",
        "\n",
        "average_transaction_amount = transaction.groupBy().agg(avg(\"amount\").alias(\"average_transaction_amount\"))\n",
        "\n",
        "average_transaction_amount.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxNKFCpFqDXy",
        "outputId": "21cd3a28-3391-4a83-f0f9-f320ce9c9ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|average_transaction_amount|\n",
            "+--------------------------+\n",
            "|1450.0                    |\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3: Identify High-Value Customers with Total Balance\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "test = accounts.groupBy(\"customer_id\").agg(F.sum('balance').alias('total_bal'))\n",
        "test1 = test.join(df_cust, \"customer_id\", 'inner')\n",
        "test_new= test1.orderBy(F.desc(\"total_bal\")).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taLTgjwgqXmQ",
        "outputId": "e23c9db3-a8ac-4369-d856-aa4711a191b4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+----------+---------+-------------+\n",
            "|customer_id|total_bal|first_name|last_name|date_of_birth|\n",
            "+-----------+---------+----------+---------+-------------+\n",
            "|          4|    12000|     Sarah|    Jones|   1988-12-03|\n",
            "|          2|    10500|      Jane|    Smith|   1992-08-21|\n",
            "|          3|     9000|     Alice|  Johnson|   1975-02-10|\n",
            "|          1|     6000|      John|      Doe|   1980-05-15|\n",
            "|          5|     3000|     David|    Brown|   1995-04-18|\n",
            "+-----------+---------+----------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4: List Employees and Their Assigned Customers\n",
        "\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"SparkDemoApp\").getOrCreate()\n",
        "df_acc_cust = accounts.join(df_cust, on = 'customer_id', how = 'inner')\n",
        "\n",
        "df_emp2 = spark.createDataFrame(employees)\n",
        "\n",
        "lec_df = df_acc_cust.join(df_emp2, on = 'employee_id', how = 'inner')\n",
        "\n",
        "lec_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mftjpgLin_13",
        "outputId": "3007b1e2-c848-4796-c970-09ee16ca40e0"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.0.0-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py:327: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+----------+------------+-------+----------+---------+-------------+---------+----------+---------+--------+\n",
            "|employee_id|customer_id|account_id|account_type|balance|first_name|last_name|date_of_birth|branch_id|first_name|last_name|position|\n",
            "+-----------+-----------+----------+------------+-------+----------+---------+-------------+---------+----------+---------+--------+\n",
            "|          1|          3|         4|    Checking|   3000|     Alice|  Johnson|   1975-02-10|        2|      Mike|  Johnson| Manager|\n",
            "|          3|          1|         2|    Checking|   1000|      John|      Doe|   1980-05-15|        2|    Robert|    Davis|  Teller|\n",
            "|          3|          3|         6|     Savings|   6000|     Alice|  Johnson|   1975-02-10|        2|    Robert|    Davis|  Teller|\n",
            "|          4|          2|         3|     Savings|   8000|      Jane|    Smith|   1992-08-21|        3|    Olivia|   Wilson|  Teller|\n",
            "|          4|          4|         7|    Checking|  12000|     Sarah|    Jones|   1988-12-03|        3|    Olivia|   Wilson|  Teller|\n",
            "|          2|          5|         8|     Savings|   3000|     David|    Brown|   1995-04-18|        3|     Emily| Williams|  Teller|\n",
            "|          2|          1|         1|     Savings|   5000|      John|      Doe|   1980-05-15|        3|     Emily| Williams|  Teller|\n",
            "|          2|          2|         5|    Checking|   2500|      Jane|    Smith|   1992-08-21|        3|     Emily| Williams|  Teller|\n",
            "+-----------+-----------+----------+------------+-------+----------+---------+-------------+---------+----------+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5: Calculate the Total Number of Transactions for Each Account Type\n",
        "\n",
        "joined_df = transaction.join(accounts, \"account_id\", \"inner\")\n",
        "\n",
        "total_transactions_by_type = joined_df.groupBy(\"account_type\").agg(count(\"transaction_id\").alias(\"total_transactions\"))\n",
        "\n",
        "total_transactions_by_type.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "283I5Vt4u_UQ",
        "outputId": "ba318372-ac24-4752-8c00-56c1879591fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+\n",
            "|account_type|total_transactions|\n",
            "+------------+------------------+\n",
            "|     Savings|                 5|\n",
            "|    Checking|                 5|\n",
            "+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6 & 7: Find Customers with No Accounts:\n",
        "\n",
        "customers_alias = customers.alias(\"c\")\n",
        "accounts_alias = accounts.alias(\"a\")\n",
        "\n",
        "customers_with_no_accounts = customers_alias.join(accounts_alias, col(\"c.customer_id\") == col(\"a.customer_id\"), \"left_anti\")\n",
        "\n",
        "customers_with_no_accounts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoLshF8K-4iv",
        "outputId": "2f796c4f-e0d7-4a87-98be-d933e260523f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+-------------+\n",
            "|customer_id|first_name|last_name|date_of_birth|\n",
            "+-----------+----------+---------+-------------+\n",
            "|          6|      Emma|   Miller|   1982-07-25|\n",
            "+-----------+----------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: List the Latest Transaction for Each Account\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "window_spec = Window.partitionBy(\"account_id\").orderBy(F.desc(\"transaction_date\"))\n",
        "\n",
        "df_transactions_with_row_number = transaction.withColumn(\"row_number\", F.row_number().over(window_spec))\n",
        "\n",
        "latest_transactions = df_transactions_with_row_number.filter(\"row_number = 1\")\n",
        "\n",
        "latest_transactions = latest_transactions.drop(\"row_number\")\n",
        "\n",
        "latest_transactions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6KpjKnJ_D4i",
        "outputId": "befa59dd-f4ec-4e25-82f8-fac83571c64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+----------------+------+-------------------+\n",
            "|transaction_id|account_id|transaction_type|amount|   transaction_date|\n",
            "+--------------+----------+----------------+------+-------------------+\n",
            "|            10|         1|         Deposit|  1200|2023-10-01 10:00:00|\n",
            "|             7|         3|      Withdrawal|   800|2023-07-08 14:15:00|\n",
            "|             6|         5|         Deposit|  2000|2023-06-12 11:30:00|\n",
            "|             9|         4|      Withdrawal|  1500|2023-09-14 09:30:00|\n",
            "|             8|         2|         Deposit|  3000|2023-08-22 16:45:00|\n",
            "+--------------+----------+----------------+------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9: Calculate the Total Withdrawals for Each Customer:\n",
        "\n",
        "trans_df = df_acc_cust.join(transaction, 'account_id')\n",
        "trans_df2 = trans_df[trans_df['transaction_type'] == 'Withdrawal']\n",
        "trans_df3 = trans_df2.select('customer_id', 'first_name', 'last_name', 'amount')\n",
        "trans_df4 = trans_df3.groupBy('customer_id', 'first_name', 'last_name').agg(F.sum('amount').alias('total_withdrwals'))\n",
        "trans_df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ4X8dm0DfeS",
        "outputId": "079ade5b-6cb3-44bd-f69f-7a6fbd2f9da5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+---------+----------------+\n",
            "|customer_id|first_name|last_name|total_withdrwals|\n",
            "+-----------+----------+---------+----------------+\n",
            "|          3|     Alice|  Johnson|            1500|\n",
            "|          2|      Jane|    Smith|            1800|\n",
            "|          1|      John|      Doe|             500|\n",
            "+-----------+----------+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 10: Find Duplicate Transactions\n",
        "\n",
        "df_dup1 = transaction.groupby('transaction_id').count().alias(\"duplicate_count\")\n",
        "df_dup = df_dup1.filter(col(\"count\" )> 1).alias(\"duplicate\")\n",
        "df_dup.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpyuJplBA19W",
        "outputId": "bbf5a62d-c61e-478f-aa28-e8a8ccf0d4e9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|transaction_id|count|\n",
            "+--------------+-----+\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYFAg-dgCZig"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}